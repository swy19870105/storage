## 存储区域网络(SAN)中各种缓存(Cache)技术的应用和比较

原创 *2016-07-28* *罗宾* [EMC易安信中国技术社区](https://mp.weixin.qq.com/s?__biz=MjM5NjY0NzAwMg==&mid=2651771242&idx=2&sn=7c4859275285a90d337d8b8258cc8978&scene=21##)

本文主要讨论了在SAN存储领域里Cache技术的应用范围和功能比较，可以为企业存储管理员等IT技术人员在制定企业级存储解决方案时提供参考。文章主要以EMC的CLARiiON 和 Symmetrix 等主流SAN存储产品为例，简要介绍SAN里涉及到的各种Cache缓存技术，同时对比各个技术的优缺点和应用场合，包括缓存使用中的最佳实践分析。由浅入深地阐述了缓存技术在后端存储阵列以及前端服务器层面越来越广泛的应用和多样化的设计与实现。最后引入了在实际生产环境下的使用缓存技术来提供生产效率的案例。

**（1）引言：**

在数据存储技术日新月异的今天，信息量也在以爆炸形式而迅猛增长。当磁盘等存储媒体介质已经不是存储行业的软肋时，大数据（Big Data）和云存储（Cloud Storage）便成为可能。各大存储厂商和研究组织也逐渐把新的焦点集中在如何提高数据存储速度和性能，从而进一步保证各种应用程序的读写达到更快速更可靠的要求得以满足。于是在当下流行的存储区域网络(SAN) 领域 ，新的提升存储性能技术就应运而生了。其中Cache缓存技术的发展和应用显得越来越重要了。

**（2）正文：**

在过去的十年中，服务器处理技术继续发展沿着摩尔定律曲线。每18个月，内存和处理能力已经翻了一倍，但是磁盘驱动器技术还没有。驱动器的转速，继续以相同的速度旋转。这导致了一个在I / O堆栈上的瓶颈，服务器和应用程序有能力以处理比磁盘驱动器可以交付的更多的I / O。这被称为I / O差距。传统的比较直接的方法是增加存储端处理器的DRAM主内存，从而能分配给控制器的读缓存（Read Cache）和写缓存（Write Cache）更多的容量，来加快后端存储的I/O吞吐量，这样就把处理I/O的任务交给了Cache和磁盘之间的通信。这里以EMC 的CLARiiON为例，首先介绍一下磁阵系统的读写缓存的概念。

一个存储系统的控制器缓存有两个部分：读缓存和写高速缓存。读缓存使用一个预读机制， 允许存储系统从硬盘预取数据。因此，应用程序时需要此数据就可以从读缓存里直接得到。存储系统内存储最近访问的数据的高速内存。为了得到更快的响应时间，所有主机写入都直接写入缓存，并在写入磁盘前向主机发回确认。写高速缓存的缓冲区，通过吸收高峰负荷优化写操作，联合小写操作，以及消除重写。你可以改变读缓存大小、写缓存大小和缓存页面大小达到最优性能。最好的尺寸的读和写缓存取决于读/写比率。一个通用的标准比读书写的都是两读/一写；即：读取占了66%的I / O。

在主存储DRAM(内存)的部署方式中，由用户决定在固态磁盘中放置哪些数据以及何时放置。用户必须进行特殊的操作来将数据迁移到固态磁盘中，而且使用到这些数据的应用程序必须被告知数据的准确位置。内存和缓存的固态 磁盘部署有两个显著的不同：在内存的部署方式中，仅有数据放置在固态磁盘上的应用程序可以提升性能。而且和缓存系统中性能随时间线性增长不同，内存部署方式可以即刻改善性能，不需要花时间预热数据。主内存分配给读、写缓存的空间越大系统处理I/O的速度就越快。这就是主内存DRAM的部署的最大优势，可以直接反应出对于来自服务器的I/O处理能力。提升对所有负载整体性能，见效快但是成本高，灵活性和可扩展性以及易维护性交差一点。

读、写缓存固然对提高存储系统整体性能很好，但是这些缓存依然来自存储控制器里的主内存，也就是DRAM。而由于内存硬件容量的制约和成本的考虑，基于RAM的系统主内存不可能无限增加，并且更重要的一个因素是，如果在使用大写缓存的情况下出现断电、宕机等不确定因素容易造成写缓存无法访问甚至数据丢失。那么就会出现缓存越大丢失的数据越多的情况。在实际生产环境中，很多客户都是因为突然的掉电导致系统内存中有来不及写入磁盘的数据而出现Dirty Cache（脏数据）如果后端存储的两个控制器都出现问题无法启动，那么这部分的缓存数据就彻底丢失了。还有就是很多核心硬件故障也会导致写缓存首先自动被禁用（Disabled），以便保证不会出现数据在写缓存内丢失的情况。

所以我们必须根据生产应用环境和以及I/O量大小及I/O特性来调整读写缓存的大小，来达到优化性能的目的。由此看来，单靠增加系统控制器的读写缓存，即单一增加系统主内存DRAM来提高存储系统整体性能还是不足的。因为内存的固态磁盘部署方式最大的缺点在于，今天最合适的数据分布方式可能并不是明天最合适的。举例来讲，假设一个非常关键的应用仅在每个月 末需要高性能，其数据必须在每月月末处理开始之前迁移到固态磁盘，并在月末处理结束之后移出。为解决这一问题，许多固态存储技术的供应商为其内存部署方式自动化软件提供自动化功能，可以自动化辅助选择和迁移数据到固态磁盘上。这些解决方案可以工作在全LUN级别或次LUN级别。此外，这些解决方案通常提供了基于策略的数据迁移功能，用户可以设置相关阈值，限制数据升级到固态磁盘上的次数和降级到普通磁盘上的次数。这些自动化分层软件解决方案目前都已应用成熟。

EMC的全自动分层存储（FAST）就是自动化分层软件解决方案中比较先进的技术之一。其实在SAN应用存储产品中，各类控制器，不论软件控制器，服务器内部的RAID控制器或者是高端外部阵列的控制器，会将固态存储技术作为前端传统磁盘存 储的一个缓存。该缓存控制器会区分出所有经常存取的数据，亦称为“热点数据”，并自动地将其迁移至固态媒介。虽然不同的缓存控制器或许有些许不同的缓存交 换算法，但最基本的想法还是通过将热点数据迁移到最高速的媒介上，提升I/O性能并降低I/O延迟来改善性能。I/O模式每时每刻都在变化，缓存控制器自 动地监控哪些数据是最常被访问的，并将其迁移至最高速的媒介，在这个过程中无需任何用户或管理员的介入。

另外FAST还具备Cache功能，如果存储系统有需求，简单讲就是Fast Cache将把一部分固态硬盘当成Cache来使用。FAST与 FAST Cache协同工作，从而基于应用程序访问各种数据块的方式将数据放置在最适当 的存储层上。自 EMC 在企业阵列的磁盘模块（通常称为 SSD）中首次部署闪存技术以来，拓展此技术在整个存储系统中的使用一直是业界的目标。IT技术日新月异，近几年里闪存技术的高性能和快速降低的每 GB 成本结合在一起导致缓存层 概念的出现。缓存层是使用企业闪存驱动器的大容量辅助缓存，介于存储处理器基于 DRAM 的主缓存和硬盘驱动器之间。在 EMC  CLARiiON、Celerra 统一存储和 VNX™ 存储系统上，此功能称为 EMC FAST Cache。

FAST Cache 可扩展存储系统的现有缓存容量，以提高整体系统性能。具体通过以下几个方式实现：将经常访问的数据映射到闪存驱动器以扩展 DRAM 缓存的功能，闪存驱动器的速度比机械式驱动器（也称为硬盘驱动器）快一个数量级，从而大大提高系统性能。它还使用闪存驱动器提供更大的可扩展缓存，与 DRAM 容量相比，闪存驱动器可以提供非常大的每驱动器容量。FAST Cache 的容量介于 73 GB 到 2 TB 之间，这比现有存储系统的可用 DRAM 缓存大得多。无需用户干预即可使应用程序体验到 FAST Cache 的性能优势。因此，EMC用闪盘作为系统主内存Cache的延伸，不存在掉电后的保护问题。

使用 FAST Cache 的一个主要应用就是能提高应用程序性能，特别是对于 I/O 活动经常不可预知的大幅度增加的工作负载。应用程序工作数据集经常被访问的部分会复制到 FAST Cache，因此应用程序可以立即大幅提高性能。利用 FAST Cache，应用程序可以通过以闪存驱动器速度处理繁重的读/写负载来实现一致的性能。另一个重要好处是降低了系统的总体拥有成本 (TCO)，这是通过减少后端硬盘驱动器上的负载实现的。FAST Cache 将大型存储容量的繁忙部分复制到闪存驱动器；因此，许多 LUN 的最繁忙区域只使用一小组闪存驱动器。这使得一大组速度较慢的驱动器可以实现通常由速度较快的驱动器提供的性能。经过一段时间后，速度较快的光纤通道驱动器可以减少数量或替换为速度较慢的光纤通道或 SATA 驱动器，同时保持相同的应用程序性能。这样就提高了存储系统的财务效率和能源效率 。

这里我举个实际生产案例来说明FAST Cache如何提高了应用程序的性能。原来在客户环境里有若干台虚机，针对150个VMware试图桌面，所有虚机启动需要20分钟，响应225毫秒，使用FAST Cache之后启动时间缩短为9分钟，响应时间缩短为50毫秒。还有我们知道Exchange Server 2010 是一个对存储系统要求很高的应用程序。而使用Exchange 2010的公司就会从EMC FAST Cache 中受益匪浅。我们做了测试，在一个单一Exchange 2010 服务器使用SATA盘作为储存的环境，启用FAST Cache测试发现IOPS获得了113%的增长。在另一个更大一些的配置达到44TB数据量的Exchange 2010环境，数据处理任务非常繁重，测试结果显示在启用FAST  Cache后STAT 盘的性能也有42%的提升。

FAST Cache 与存储系统缓存的比较，FAST Cache 是基于半导体的存储技术。它在存储系统的 DRAM 缓存（速度较快但容量有限）与机械式硬盘驱动器（速度较慢但容量较高）之间提供一个基于闪存的大容量辅助缓存层。

DRAM 内存与 FAST Cache 缓存的比较

特征      DRAM 缓存      FAST Cache 缓存

位置      它最接近 CPU，并且延迟最低。      与 DRAM 缓存相比，它距离 CPU 较远并且较慢。

粒度      它具有非常高的粒度，粒度实际上是 I/O 大小。缓存页面大小可由用户配置，可介于2KB 到16KB 之间。      它在 64 KB 粒度的范围内运行。

可升级性      不可升级。      可在各种型号中升级，相关选项取决于存储系统型号和闪存驱动器类型。

操作      它对读操作和写操作分别使用单独的区域。      它使用单个区域来完成读操作和写操作。

容量      与 FAST Cache 相比，它的大小有限。      可以扩展到非常大的容量。

范围      它支持 FAST Cache LUN 以及其他 LUN。      它允许您在所选 RAID 组 LUN 或存储池上启用 FAST Cache。

响应时间      响应时间大约为几毫微秒到几微秒。      响应时间大约为几微秒到几毫秒。

可用性      出现故障时，需要合格人员进行更换。      出现故障时，另一闪存驱动器热备盘自动取代出现故障的驱动器，客户可更换故障组件。

电源故障      它的内容具有易失性；因此不能经受断电。      它的内容是非易失性的，可以经受断电。

如何提高提升应用程序性能是储存行业一个永恒的话题。最近几年闪存技术的兴起和飞速发展让很多业内人士又看到了新的机会。我们知道SAS和SATA驱动器给数据库提供了不凡的性能容量比，但基于物理旋转的磁盘注定不能够提供最佳的性能。 于是把闪存驱动器加入到磁阵中就发现可以提供一个更高数量级的性能。 现在在市场上有一个新的服务器闪存缓存技术，提供了更大的性能。就是说 把Flash闪存放置到装有PCIe卡的服务器上，就可以加速甚至得到另一个数量级闪存驱动器的性能。

EMC VFCache 就是一种优秀的服务器闪存缓存解决方案，可利用智能缓存软件和 PCIe 闪存技术缩短延迟并提高吞吐量，从而大幅提升应用程序性能。VFCache 可加快数据块 I/O 读取速度和保护数据，方法是使用到网络存储的直写缓存，提供持久的高可用性、可靠性、数据完整性和灾难恢复。与基于阵列的 EMC 全自动存储分层 (FAST) 软件配合使用时，VFCache 可创建从应用程序到数据存储区的最高效和最智能的 I/O 路径。并最终衍生出针对物理和虚拟环境的性能、智能和保护进行动态优化的网络基础架构。VFCache 与阵列上的 FAST VP（Virtual Provision） 和 FAST Cache 互为补充，但它并不要求存储阵列使用 FAST VP 或 FAST Cache。VFCache 作为一种服务器端只读缓存，可将 EMC 全自动存储层 (FAST) 策略扩展到服务器。VFCache 动态缓存引擎不仅会自动识别频繁访问的数据，还会自动将该数据升级到 PCIe 卡上的闪存中。如此一来，不但使来自 SAN 和共享阵列的 I/O 压力得到缓解，而且也提高了应用程序性能。由于频繁访问的数据位于服务器内，使 I/O 服务次数大幅减少。因此，服务器可支持更多的虚拟机和/或应用程序可交付更多的事务。

VFCache 独立于 FAST Cache 和 FAST VP 运行。VFCache 是一种专用的服务器端只读缓存，而 FAST Cache 是一种支持读写操作的共享阵列端缓存。上述二者均属暂时性缓存，而 FAST VP 则是在基于阵列的存储池内的层之间半永久性地移动数据。借助于 EMC 存储阵列缓存和分层技术中的智能优势，FAST VP 算法允许阵列集中资源来处理所有工作负载中要求最高的部分。这三种技术旨在共同确保以最低的延迟为最常访问的信息提供服务。VFCache、FAST Cache 和 FAST三者相结合，可进一步简化数据连续体系间的数据传递。

同样，我们也找了个实际案例来说明VFCache如何提高了应用程序的性能。在一个使用VFCache 配合FAST Cache 来加速联机事务处理系统（OLTP）Oracle DB11gR2的环境里，我们发现在配置了VFCache后，系统的吞吐量，每分钟交易量，是基线配置(Baseline Configuration)的2.5倍，而延时时间（Latency）却减少了30%。如果再同时配合启用FAST Cache功能，系统的吞吐量及每分钟交易量，是基线配置的7.8倍，而延时时间减少了20%。

 

**（3）结论：**

回头看来，总结我遇到的这些实际案例中，一些用户选择了固态磁盘缓存的部署方式，而另一些则选择主存储(DRAM)方式。由于每种方式都有其优点，这使得许多客户开始时选择缓存的方式，而之后又为其解决方案额外增加了内存方式的支持选项，反之亦然。主内存是基本配置，用户可以根据EMC官方文档找到自己型号机器所对应的最佳推荐读/写缓存配置。但是内存是不保护数据的，一旦断电数据将全部丢失。这将是它永远的软肋。当存储系统的FLARE® 版本 升级到30以上后，并且根据条件能够使用Flash闪存驱动器，那么我们极力推荐用户使用EMC FAST VP及FAST Cache来进一步提高整体系统性，因为闪存驱动器的速度比机械式驱动器快一个数量级。FAST Cache 的容量介于 73 GB 到 2 TB 之间，这比现有存储系统的可用 DRAM 缓存大得多。但是FAST CACHE并非适用于所有I/O类型。例如，连续大I/O数据流或许根本不会促使数据被提升（Promote）至FAST Cache，因为这些I/O不会多次访问同一个64KB数据块（chunk）。于是人们开始把目光从后端的存储转移到了前端服务器。VFCache就是一个软硬件完美结合的最新服务器端闪存缓存解决方案。在内存中的应用缓存数据只能加速某个应用，但VFCache可以加速 所有连接到它的源存储，也就是我们通常所说的LUN。当然现阶段VFCache还不支持Cluster，希望能在下一版VFCache中实现了共享磁盘环境和Active/Active集群的支持。综上我们不难看出，主内存DRAM，FAST Cache 还有VFCache 都是提升存储性能的好办法，三者如果能够根据用户实际应用程序的特点以及硬件设备条件来搭配使用必将给用户带来前所未有的性能提升体验，同时也会降低运维成本，提高客户满意度和企业生产效率。